\documentclass{article}

\title{02258 Parallel Computer Systems Formula Collection}
\author{Jonas Birkedal Dudal Jensen (s203849)}
\date{}

\begin{document}
	\maketitle
	\newpage

	\tableofcontents
	\newpage

	\section{Pipeline Speedup, Throughput, and Results per Cycle (p. 10)}
		Image of pipeline can be seen in figure 1.5 page 9, and figure 1.6 on page 11 shows the throughput for different $m$.

		\subsection{Speedup}
		\begin{equation}
			\frac{T_{seq}}{T_{pipe}}=\frac{mN}{N+m-1}
		\end{equation}
		Where $T_{seq}$ is the sequential execution time, $T_{pipe}$ is the pipelined execution time, $m$ is the depth of the pipeline and $N$ is the number of times it should be executed.

		\subsection{Throughput}
		\begin{equation}
			\frac{N}{T_{pipe}}=\frac{1}{1+\frac{m-1}{N}}
		\end{equation}
		Where $N$ is the number of times it should be executed, $T_{pipe}$ is the pipelined execution time, and $m$ is the depth of the pipeline.

		\subsection{Results per cycle}
		\begin{equation}
			N_c=\frac{(m-1)p}{1-p}
		\end{equation}
		Where $N_c$ is the size of the pipeline resulting in $p$ results per cycle, and $m$ is the depth of the pipeline.
	
	\section{Caches and speed (p. 16)}
		Image of cache performance gain agains cache reuse ratio is seen in figure 1.9 page 16.

		\begin{equation}
			G(\tau, \beta)=\frac{T_m}{T_{av}}=\frac{\tau}{\beta+\tau(1-\beta)}
		\end{equation}
		Where $G$ is the performance gain, $T_m$ is the access time to main memory, $T_{av}$ is the average access time, $\tau$ is the speedup factor of the memory compared to main memory, and $\beta$ is the cache reuse ratio.
	
	\section{Prefetching (p. 21)}
		An example of prefetching is shown in figure 1.13 on page 22.
	
		\begin{equation}
			P=1+\frac{T_l B}{L_c}
		\end{equation}
		Where $P$ is the number of prefetches required to saturate the pipeline, $T_l$ is the latency of a miss, $B$ is the bandwith, and $L_c$ is the length of a cache line.
	
	\section{Machine and Code Balance (p. 63)}
		\subsection{Machine Balance}
			\begin{equation}
				B_m=\frac{b_{max}}{P_{max}}
			\end{equation}
			Where $B_m$ is the machine balance of the machine, $b_{max}$ is the maximal memory bandwith (Words$/$sec), and $P_{max}$ is the peak performance (Flops$/$sec).

		\subsection{Code Balance}
			\begin{equation}
				B_c=\frac{d}{o}
			\end{equation}
			Where $B_c$ is the code balance of the program, $d$ is the data trafic per flop (Words$/$sec), and $o$ is the number of floating point ops (Flops$/$sec).
		
		\subsection{Computational Intensity}
			\begin{equation}
				I=\frac{1}{B_c}=\frac{o}{d}
			\end{equation}
			Where $I$ is the computational intensity of the program, $B_c$ is the code balance of the program, $d$ is the data trafic per flop (Words$/$sec), and $o$ is the number of floating point ops (Flops$/$sec).
		
		\subsection{Lightspeed}
			\begin{equation}
				l=\min\left(1,\frac{B_m}{B_c}\right)
			\end{equation}
			Where $l$ is the lightspeed of a loop, or how much the loop is bandwith limited, $B_m$ is the machine balance of the machine, and $B_c$ is the code balance of the program.
		
		\subsection{Performance from Lightspeed}
			For STREAM specific performances, see (3.5) page 68.
			\begin{equation}
				P=lP_{max}=\min\left(P_{max},\frac{b_{max}}{B_c}\right)
			\end{equation}
			Where $P$ is the performance of running the code on the machine, $l$ is the lightspeed of a loop, $P_{max}$ is the peak performance, $b_{max}$ is the maximal memory bandwith, and $B_c$ is the code balance of the program.
\end{document}